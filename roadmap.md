

LLM application dev
- LLM openai interface basic concepts
  - general params
      - https://www.bilibili.com/video/BV1nK421Y72d
      - temperature
      - top k
      - top p
      - num_beams
      - logprobs
      - top_logprobs
  - context size
    - what is token
  - image
- prompt engineering
  - [普通人如何通过DeepSeek提升工作效率](https://www.bilibili.com/video/BV1UdAVeXECY)
  - [12个精选prompt框架 ](https://waytoagi.feishu.cn/wiki/ByWEw79g5icSQGkAcNrcgbBonUc)
  - https://www.promptingguide.ai/
  - https://llmnanban.akmmusai.pro/Introductory/Prompt-Elements/
  - https://www.leeboonstra.dev/prompt-engineering/prompt_engineering_guide6/ 系列
  - https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/prompt-engineering?tabs=chat 
- RAG & ReRank
- MCP (function call)
- agent & workflow

LLM inference
- LLM 推理过程
    - prefill
    - decode
- 模型占用 & 推理占用
    - 模型占用 xB -> 2x GB (float16),  llama-8b -> 16GB, llama-1b -> 2GB
    - [kv cache 计算](https://lmcache.ai/kv_cache_calculator.html)

todo 
- https://www.armcvai.cn/categories.html